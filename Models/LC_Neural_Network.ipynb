{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Zd81MQ8RUv",
        "outputId": "9aab2cdb-6f89-4b3c-c1ff-bc79c8acc629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCQKaMC4V9pT"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB2PdgIJJYhR",
        "outputId": "fc1f402a-adc2-43f9-9aa4-5416c3cb0021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "## Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTP4RSXMWPuM"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQU34HsGq0v-",
        "outputId": "cd8b30f9-7988-4684-dcfe-e75f487b806b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of infinity values: 0\n",
            "Number of nan values: 1300\n",
            "x_train shape: (1266, 738)\n",
            "x_val shape: (231, 738)\n",
            "x_test shape: (369, 738)\n",
            "y_train shape: (1266,)\n",
            "y_val shape: (231,)\n",
            "y_test shape: (369,)\n",
            "x_train min: 0.0\n",
            "x_train max: 1.0000000000000004\n",
            "name of first sample in test: K01126.02\n"
          ]
        }
      ],
      "source": [
        "## Preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load input file\n",
        "input_filepath = '/content/drive/MyDrive/Colab Notebooks/koi_project/koi_features_correct.csv' # Your tsfresh_features.csv\n",
        "data = pd.read_csv(input_filepath)\n",
        "\n",
        "# Cancel colums with only one unique value\n",
        "unique_value_column = data.columns[data.nunique() <= 1]\n",
        "data = data.drop(unique_value_column, axis=1)\n",
        "\n",
        "# Remove samples with infinity values\n",
        "infinity_count = (data == np.inf).sum().sum()\n",
        "print(\"Number of infinity values:\", infinity_count)\n",
        "infinity_mask = data.isin([np.inf, -np.inf]).any(axis=1)\n",
        "data = data[~infinity_mask]\n",
        "\n",
        "# Fill nan values with zero\n",
        "nan_count = data.isna().sum().sum()\n",
        "print(\"Number of nan values:\", nan_count)\n",
        "data = data.fillna(0)\n",
        "\n",
        "# Split into training, validation and training set\n",
        "train = data[:-600]\n",
        "val = data[-600:-369]\n",
        "test = data[-369:]\n",
        "\n",
        "# Split into x and y\n",
        "x_train, x_val, x_test = train.iloc[:, 1:-1], val.iloc[:, 1:-1], test.iloc[:, 1:-1]\n",
        "y_train, y_val, y_test = train.iloc[:, -1], val.iloc[:, -1], test.iloc[:, -1]\n",
        "\n",
        "# Scale features\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_val = scaler.transform(x_val)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# Display shapes of input data\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_val shape:\", x_val.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "print(\"x_train min:\", x_train.min().min())\n",
        "print(\"x_train max:\", x_train.max().max())\n",
        "print(\"name of first sample in test:\", test.iloc[0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wnwQKtLrT1gu"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)  # For PyTorch\n",
        "    torch.cuda.manual_seed(seed)  # For CUDA\n",
        "    torch.cuda.manual_seed_all(seed)  # For multi-GPU (if used)\n",
        "    np.random.seed(seed)  # For NumPy\n",
        "    random.seed(seed)  # For Python's built-in random module\n",
        "    torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfheLTGnWXhv"
      },
      "source": [
        "# Model Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "IMA9gIQPEFAV"
      },
      "outputs": [],
      "source": [
        "## Model construction\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define neural network\n",
        "class ExoplanetModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ExoplanetModel, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(256, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_dim = x_train.shape[1]\n",
        "model = ExoplanetModel(input_dim)\n",
        "\n",
        "# Move the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00003)\n",
        "\n",
        "# Define StepLR scheduler\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvlZTt7fWct3"
      },
      "source": [
        "# Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Y-RhUOpYLIME"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_validation_loss = float('inf')\n",
        "        self.best_model = None\n",
        "        self.best_epoch = None  # Track the epoch with the best validation loss\n",
        "\n",
        "    def early_stop(self, validation_loss, epoch, model=None):\n",
        "        if validation_loss < self.best_validation_loss - self.min_delta:\n",
        "            # Update best validation loss and epoch\n",
        "            self.best_validation_loss = validation_loss\n",
        "            self.best_epoch = epoch\n",
        "            self.counter = 0\n",
        "            if model:\n",
        "                self.best_model = model.state_dict()  # Save the best model\n",
        "        elif validation_loss > (self.best_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True  # Stop training\n",
        "        return False\n",
        "\n",
        "    def get_best_model(self):\n",
        "        return self.best_model\n",
        "\n",
        "    def get_best_epoch(self):\n",
        "        return self.best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "nJ38eqiLFz5J"
      },
      "outputs": [],
      "source": [
        "## Training and validation\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert data to Pytorch tensors\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Move data to GPU\n",
        "x_train_tensor = x_train_tensor.to(device)\n",
        "y_train_tensor = y_train_tensor.to(device)\n",
        "x_val_tensor = x_val_tensor.to(device)\n",
        "y_val_tensor = y_val_tensor.to(device)\n",
        "\n",
        "# Create DataLoader for mini-batch training\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, worker_init_fn=lambda worker_id: np.random.seed(1 + worker_id))\n",
        "val_data = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False, worker_init_fn=lambda worker_id: np.random.seed(1 + worker_id))\n",
        "\n",
        "# Training function\n",
        "def train(model, criterion, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # move data to GPU\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # forward\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad() # clean gradients for previous step\n",
        "        loss.backward() # calculate gradients\n",
        "        optimizer.step() # update weights\n",
        "\n",
        "        # accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # accumulate preds\n",
        "        preds = (outputs > 0.5).float()\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y_batch.cpu().numpy())\n",
        "    # compute loss\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # compute accuracy\n",
        "    epoch_accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "# Validation function\n",
        "def predict(model, criterion, val_loader, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # prevent gradient tracking\n",
        "        for x_batch, y_batch in val_loader:\n",
        "            # move data to GPU\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            # forward\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            # accumulate loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # accumulate preds\n",
        "            preds = (outputs > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y_batch.cpu().numpy())\n",
        "    # compute loss\n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "\n",
        "    # compute accuracy\n",
        "    epoch_accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    # compute metrics\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    report = classification_report(all_labels, all_preds, target_names=['0', '1'])\n",
        "\n",
        "    return epoch_loss, epoch_accuracy, report\n",
        "\n",
        "# Training loop\n",
        "import matplotlib.pyplot as plt\n",
        "early_stopper = EarlyStopper(patience=30, min_delta=0.001) # initialize early stopping\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, device, epochs):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_accuracy = train(model, criterion, optimizer, train_loader, device)\n",
        "        val_loss, val_accuracy, report = predict(model, criterion, val_loader, device)\n",
        "\n",
        "        # Step the scheduler\n",
        "        #scheduler.step()\n",
        "\n",
        "        # Early stopping\n",
        "        if early_stopper.early_stop(val_loss, epoch, model):\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            model.load_state_dict(early_stopper.get_best_model())  # Load the best model\n",
        "            break\n",
        "\n",
        "        # Print\n",
        "        print(f\"Epoch[{epoch+1}/{epochs}]\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "        print(report)\n",
        "\n",
        "        # Track losses\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    # Plot losses\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')\n",
        "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Kc5g-YPVDrA",
        "outputId": "59203d74-9f37-46df-d55a-0868a59f71e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch[1/1000]\n",
            "Train Loss: 0.7813, Train Accuracy: 0.3594\n",
            "Val Loss: 0.6906, Val Accuracy: 0.4935\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.82      0.60       107\n",
            "           1       0.58      0.21      0.31       124\n",
            "\n",
            "    accuracy                           0.49       231\n",
            "   macro avg       0.53      0.52      0.45       231\n",
            "weighted avg       0.53      0.49      0.44       231\n",
            "\n",
            "Epoch[2/1000]\n",
            "Train Loss: 0.7516, Train Accuracy: 0.4060\n",
            "Val Loss: 0.6794, Val Accuracy: 0.6234\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.20      0.33       107\n",
            "           1       0.59      0.99      0.74       124\n",
            "\n",
            "    accuracy                           0.62       231\n",
            "   macro avg       0.77      0.59      0.53       231\n",
            "weighted avg       0.76      0.62      0.55       231\n",
            "\n",
            "Epoch[3/1000]\n",
            "Train Loss: 0.7239, Train Accuracy: 0.4621\n",
            "Val Loss: 0.6645, Val Accuracy: 0.6667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.34      0.48       107\n",
            "           1       0.62      0.95      0.75       124\n",
            "\n",
            "    accuracy                           0.67       231\n",
            "   macro avg       0.74      0.64      0.62       231\n",
            "weighted avg       0.73      0.67      0.63       231\n",
            "\n",
            "Epoch[4/1000]\n",
            "Train Loss: 0.7037, Train Accuracy: 0.4992\n",
            "Val Loss: 0.6466, Val Accuracy: 0.6883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.49      0.59       107\n",
            "           1       0.66      0.86      0.75       124\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.71      0.67      0.67       231\n",
            "weighted avg       0.70      0.69      0.68       231\n",
            "\n",
            "Epoch[5/1000]\n",
            "Train Loss: 0.6845, Train Accuracy: 0.5458\n",
            "Val Loss: 0.6311, Val Accuracy: 0.6840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.58      0.63       107\n",
            "           1       0.68      0.77      0.72       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.68      0.68       231\n",
            "weighted avg       0.68      0.68      0.68       231\n",
            "\n",
            "Epoch[6/1000]\n",
            "Train Loss: 0.6717, Train Accuracy: 0.5711\n",
            "Val Loss: 0.6217, Val Accuracy: 0.6840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.64      0.65       107\n",
            "           1       0.70      0.73      0.71       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.68      0.68       231\n",
            "weighted avg       0.68      0.68      0.68       231\n",
            "\n",
            "Epoch[7/1000]\n",
            "Train Loss: 0.6570, Train Accuracy: 0.6035\n",
            "Val Loss: 0.6166, Val Accuracy: 0.6840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.65      0.66       107\n",
            "           1       0.70      0.71      0.71       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.68      0.68       231\n",
            "weighted avg       0.68      0.68      0.68       231\n",
            "\n",
            "Epoch[8/1000]\n",
            "Train Loss: 0.6475, Train Accuracy: 0.6264\n",
            "Val Loss: 0.6136, Val Accuracy: 0.6797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.65      0.65       107\n",
            "           1       0.70      0.70      0.70       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.68      0.68       231\n",
            "weighted avg       0.68      0.68      0.68       231\n",
            "\n",
            "Epoch[9/1000]\n",
            "Train Loss: 0.6381, Train Accuracy: 0.6406\n",
            "Val Loss: 0.6109, Val Accuracy: 0.6970\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.68      0.68       107\n",
            "           1       0.72      0.71      0.72       124\n",
            "\n",
            "    accuracy                           0.70       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.70      0.70      0.70       231\n",
            "\n",
            "Epoch[10/1000]\n",
            "Train Loss: 0.6268, Train Accuracy: 0.6698\n",
            "Val Loss: 0.6097, Val Accuracy: 0.6840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67       107\n",
            "           1       0.71      0.69      0.70       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.68      0.68       231\n",
            "weighted avg       0.69      0.68      0.68       231\n",
            "\n",
            "Epoch[11/1000]\n",
            "Train Loss: 0.6186, Train Accuracy: 0.6761\n",
            "Val Loss: 0.6081, Val Accuracy: 0.6883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.68      0.67       107\n",
            "           1       0.72      0.69      0.70       124\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.69      0.69      0.69       231\n",
            "weighted avg       0.69      0.69      0.69       231\n",
            "\n",
            "Epoch[12/1000]\n",
            "Train Loss: 0.6070, Train Accuracy: 0.6769\n",
            "Val Loss: 0.6056, Val Accuracy: 0.6970\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.66      0.67       107\n",
            "           1       0.71      0.73      0.72       124\n",
            "\n",
            "    accuracy                           0.70       231\n",
            "   macro avg       0.70      0.69      0.69       231\n",
            "weighted avg       0.70      0.70      0.70       231\n",
            "\n",
            "Epoch[13/1000]\n",
            "Train Loss: 0.5925, Train Accuracy: 0.7125\n",
            "Val Loss: 0.6035, Val Accuracy: 0.7013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.66      0.67       107\n",
            "           1       0.72      0.73      0.73       124\n",
            "\n",
            "    accuracy                           0.70       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.70      0.70      0.70       231\n",
            "\n",
            "Epoch[14/1000]\n",
            "Train Loss: 0.5870, Train Accuracy: 0.7243\n",
            "Val Loss: 0.6026, Val Accuracy: 0.7056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.66      0.68       107\n",
            "           1       0.72      0.74      0.73       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[15/1000]\n",
            "Train Loss: 0.5820, Train Accuracy: 0.7314\n",
            "Val Loss: 0.6012, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.67      0.69       107\n",
            "           1       0.73      0.75      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[16/1000]\n",
            "Train Loss: 0.5678, Train Accuracy: 0.7417\n",
            "Val Loss: 0.6002, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.67      0.69       107\n",
            "           1       0.73      0.76      0.74       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[17/1000]\n",
            "Train Loss: 0.5601, Train Accuracy: 0.7599\n",
            "Val Loss: 0.5986, Val Accuracy: 0.7100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.65      0.68       107\n",
            "           1       0.72      0.76      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[18/1000]\n",
            "Train Loss: 0.5538, Train Accuracy: 0.7757\n",
            "Val Loss: 0.5975, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.64      0.68       107\n",
            "           1       0.72      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[19/1000]\n",
            "Train Loss: 0.5442, Train Accuracy: 0.7725\n",
            "Val Loss: 0.5964, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.67       107\n",
            "           1       0.71      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[20/1000]\n",
            "Train Loss: 0.5422, Train Accuracy: 0.7954\n",
            "Val Loss: 0.5957, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[21/1000]\n",
            "Train Loss: 0.5299, Train Accuracy: 0.8049\n",
            "Val Loss: 0.5959, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[22/1000]\n",
            "Train Loss: 0.5239, Train Accuracy: 0.8081\n",
            "Val Loss: 0.5947, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[23/1000]\n",
            "Train Loss: 0.5259, Train Accuracy: 0.8041\n",
            "Val Loss: 0.5929, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.63      0.67       107\n",
            "           1       0.71      0.80      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.71       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[24/1000]\n",
            "Train Loss: 0.5128, Train Accuracy: 0.8294\n",
            "Val Loss: 0.5926, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.79      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[25/1000]\n",
            "Train Loss: 0.5061, Train Accuracy: 0.8397\n",
            "Val Loss: 0.5914, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       107\n",
            "           1       0.72      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.71       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[26/1000]\n",
            "Train Loss: 0.4987, Train Accuracy: 0.8389\n",
            "Val Loss: 0.5900, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.69       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[27/1000]\n",
            "Train Loss: 0.4996, Train Accuracy: 0.8294\n",
            "Val Loss: 0.5883, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.63      0.68       107\n",
            "           1       0.71      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[28/1000]\n",
            "Train Loss: 0.4913, Train Accuracy: 0.8412\n",
            "Val Loss: 0.5888, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[29/1000]\n",
            "Train Loss: 0.4874, Train Accuracy: 0.8468\n",
            "Val Loss: 0.5875, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[30/1000]\n",
            "Train Loss: 0.4751, Train Accuracy: 0.8681\n",
            "Val Loss: 0.5878, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.67       107\n",
            "           1       0.71      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[31/1000]\n",
            "Train Loss: 0.4743, Train Accuracy: 0.8610\n",
            "Val Loss: 0.5881, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.64      0.68       107\n",
            "           1       0.72      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[32/1000]\n",
            "Train Loss: 0.4702, Train Accuracy: 0.8689\n",
            "Val Loss: 0.5862, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       107\n",
            "           1       0.72      0.79      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.71       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[33/1000]\n",
            "Train Loss: 0.4627, Train Accuracy: 0.8807\n",
            "Val Loss: 0.5856, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       107\n",
            "           1       0.72      0.79      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.71       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[34/1000]\n",
            "Train Loss: 0.4647, Train Accuracy: 0.8736\n",
            "Val Loss: 0.5839, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.64      0.69       107\n",
            "           1       0.72      0.81      0.77       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[35/1000]\n",
            "Train Loss: 0.4487, Train Accuracy: 0.8831\n",
            "Val Loss: 0.5837, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.79      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[36/1000]\n",
            "Train Loss: 0.4485, Train Accuracy: 0.8957\n",
            "Val Loss: 0.5825, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[37/1000]\n",
            "Train Loss: 0.4388, Train Accuracy: 0.9052\n",
            "Val Loss: 0.5813, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.63      0.68       107\n",
            "           1       0.72      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.72       231\n",
            "\n",
            "Epoch[38/1000]\n",
            "Train Loss: 0.4446, Train Accuracy: 0.8839\n",
            "Val Loss: 0.5796, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.62      0.68       107\n",
            "           1       0.72      0.83      0.77       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.74      0.72      0.72       231\n",
            "weighted avg       0.74      0.73      0.73       231\n",
            "\n",
            "Epoch[39/1000]\n",
            "Train Loss: 0.4374, Train Accuracy: 0.8910\n",
            "Val Loss: 0.5815, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.65      0.69       107\n",
            "           1       0.72      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[40/1000]\n",
            "Train Loss: 0.4270, Train Accuracy: 0.9131\n",
            "Val Loss: 0.5803, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.69       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[41/1000]\n",
            "Train Loss: 0.4247, Train Accuracy: 0.9036\n",
            "Val Loss: 0.5794, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.69       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[42/1000]\n",
            "Train Loss: 0.4203, Train Accuracy: 0.9092\n",
            "Val Loss: 0.5799, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.69       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[43/1000]\n",
            "Train Loss: 0.4144, Train Accuracy: 0.9210\n",
            "Val Loss: 0.5794, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.79      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[44/1000]\n",
            "Train Loss: 0.4132, Train Accuracy: 0.9163\n",
            "Val Loss: 0.5775, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.64      0.69       107\n",
            "           1       0.72      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[45/1000]\n",
            "Train Loss: 0.4080, Train Accuracy: 0.9273\n",
            "Val Loss: 0.5767, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[46/1000]\n",
            "Train Loss: 0.4044, Train Accuracy: 0.9281\n",
            "Val Loss: 0.5766, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.69       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[47/1000]\n",
            "Train Loss: 0.4001, Train Accuracy: 0.9218\n",
            "Val Loss: 0.5762, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.65      0.69       107\n",
            "           1       0.73      0.79      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[48/1000]\n",
            "Train Loss: 0.3981, Train Accuracy: 0.9265\n",
            "Val Loss: 0.5759, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.65      0.69       107\n",
            "           1       0.73      0.79      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[49/1000]\n",
            "Train Loss: 0.3909, Train Accuracy: 0.9376\n",
            "Val Loss: 0.5743, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.65      0.70       107\n",
            "           1       0.73      0.81      0.77       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.74      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.73       231\n",
            "\n",
            "Epoch[50/1000]\n",
            "Train Loss: 0.3840, Train Accuracy: 0.9447\n",
            "Val Loss: 0.5733, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.65      0.70       107\n",
            "           1       0.73      0.81      0.77       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.74      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.73       231\n",
            "\n",
            "Epoch[51/1000]\n",
            "Train Loss: 0.3802, Train Accuracy: 0.9447\n",
            "Val Loss: 0.5729, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.64      0.69       107\n",
            "           1       0.72      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[52/1000]\n",
            "Train Loss: 0.3785, Train Accuracy: 0.9431\n",
            "Val Loss: 0.5721, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.64      0.69       107\n",
            "           1       0.72      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[53/1000]\n",
            "Train Loss: 0.3805, Train Accuracy: 0.9297\n",
            "Val Loss: 0.5707, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.64      0.69       107\n",
            "           1       0.73      0.81      0.77       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.74      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.73       231\n",
            "\n",
            "Epoch[54/1000]\n",
            "Train Loss: 0.3761, Train Accuracy: 0.9408\n",
            "Val Loss: 0.5711, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.65      0.69       107\n",
            "           1       0.72      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[55/1000]\n",
            "Train Loss: 0.3687, Train Accuracy: 0.9455\n",
            "Val Loss: 0.5709, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.65      0.69       107\n",
            "           1       0.72      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[56/1000]\n",
            "Train Loss: 0.3668, Train Accuracy: 0.9463\n",
            "Val Loss: 0.5716, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[57/1000]\n",
            "Train Loss: 0.3604, Train Accuracy: 0.9573\n",
            "Val Loss: 0.5703, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       107\n",
            "           1       0.72      0.79      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.71       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[58/1000]\n",
            "Train Loss: 0.3570, Train Accuracy: 0.9542\n",
            "Val Loss: 0.5690, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.64      0.68       107\n",
            "           1       0.72      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.72       231\n",
            "\n",
            "Epoch[59/1000]\n",
            "Train Loss: 0.3535, Train Accuracy: 0.9573\n",
            "Val Loss: 0.5685, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.64      0.68       107\n",
            "           1       0.72      0.81      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.72       231\n",
            "\n",
            "Epoch[60/1000]\n",
            "Train Loss: 0.3518, Train Accuracy: 0.9566\n",
            "Val Loss: 0.5684, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68       107\n",
            "           1       0.72      0.80      0.76       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[61/1000]\n",
            "Train Loss: 0.3478, Train Accuracy: 0.9558\n",
            "Val Loss: 0.5686, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       107\n",
            "           1       0.72      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.71       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[62/1000]\n",
            "Train Loss: 0.3461, Train Accuracy: 0.9510\n",
            "Val Loss: 0.5684, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[63/1000]\n",
            "Train Loss: 0.3403, Train Accuracy: 0.9605\n",
            "Val Loss: 0.5679, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[64/1000]\n",
            "Train Loss: 0.3396, Train Accuracy: 0.9581\n",
            "Val Loss: 0.5682, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[65/1000]\n",
            "Train Loss: 0.3356, Train Accuracy: 0.9637\n",
            "Val Loss: 0.5675, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[66/1000]\n",
            "Train Loss: 0.3326, Train Accuracy: 0.9605\n",
            "Val Loss: 0.5685, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.69      0.70       107\n",
            "           1       0.74      0.75      0.74       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[67/1000]\n",
            "Train Loss: 0.3261, Train Accuracy: 0.9692\n",
            "Val Loss: 0.5654, Val Accuracy: 0.7100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.64      0.67       107\n",
            "           1       0.71      0.77      0.74       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.70      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[68/1000]\n",
            "Train Loss: 0.3268, Train Accuracy: 0.9645\n",
            "Val Loss: 0.5661, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.66      0.69       107\n",
            "           1       0.73      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[69/1000]\n",
            "Train Loss: 0.3258, Train Accuracy: 0.9668\n",
            "Val Loss: 0.5633, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.67       107\n",
            "           1       0.71      0.78      0.75       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[70/1000]\n",
            "Train Loss: 0.3178, Train Accuracy: 0.9700\n",
            "Val Loss: 0.5641, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.65      0.68       107\n",
            "           1       0.72      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[71/1000]\n",
            "Train Loss: 0.3126, Train Accuracy: 0.9708\n",
            "Val Loss: 0.5659, Val Accuracy: 0.7403\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.70      0.71       107\n",
            "           1       0.75      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.74      0.74      0.74       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[72/1000]\n",
            "Train Loss: 0.3094, Train Accuracy: 0.9747\n",
            "Val Loss: 0.5650, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.70       107\n",
            "           1       0.73      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[73/1000]\n",
            "Train Loss: 0.3093, Train Accuracy: 0.9739\n",
            "Val Loss: 0.5659, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.70      0.70       107\n",
            "           1       0.74      0.75      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[74/1000]\n",
            "Train Loss: 0.3046, Train Accuracy: 0.9763\n",
            "Val Loss: 0.5664, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71       107\n",
            "           1       0.75      0.75      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[75/1000]\n",
            "Train Loss: 0.3031, Train Accuracy: 0.9771\n",
            "Val Loss: 0.5643, Val Accuracy: 0.7403\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.70      0.71       107\n",
            "           1       0.75      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.74      0.74      0.74       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[76/1000]\n",
            "Train Loss: 0.3000, Train Accuracy: 0.9771\n",
            "Val Loss: 0.5623, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.69      0.71       107\n",
            "           1       0.74      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[77/1000]\n",
            "Train Loss: 0.2949, Train Accuracy: 0.9771\n",
            "Val Loss: 0.5620, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.69      0.70       107\n",
            "           1       0.74      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[78/1000]\n",
            "Train Loss: 0.2905, Train Accuracy: 0.9787\n",
            "Val Loss: 0.5597, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.70       107\n",
            "           1       0.73      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.72       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[79/1000]\n",
            "Train Loss: 0.2899, Train Accuracy: 0.9834\n",
            "Val Loss: 0.5604, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70       107\n",
            "           1       0.74      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[80/1000]\n",
            "Train Loss: 0.2868, Train Accuracy: 0.9810\n",
            "Val Loss: 0.5612, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.70      0.71       107\n",
            "           1       0.75      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[81/1000]\n",
            "Train Loss: 0.2857, Train Accuracy: 0.9771\n",
            "Val Loss: 0.5613, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.70      0.71       107\n",
            "           1       0.75      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[82/1000]\n",
            "Train Loss: 0.2818, Train Accuracy: 0.9826\n",
            "Val Loss: 0.5601, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.70      0.71       107\n",
            "           1       0.75      0.77      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[83/1000]\n",
            "Train Loss: 0.2776, Train Accuracy: 0.9842\n",
            "Val Loss: 0.5648, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.71      0.71       107\n",
            "           1       0.75      0.74      0.74       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[84/1000]\n",
            "Train Loss: 0.2773, Train Accuracy: 0.9818\n",
            "Val Loss: 0.5627, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.71      0.71       107\n",
            "           1       0.75      0.76      0.76       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[85/1000]\n",
            "Train Loss: 0.2794, Train Accuracy: 0.9818\n",
            "Val Loss: 0.5665, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.72      0.71       107\n",
            "           1       0.75      0.73      0.74       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[86/1000]\n",
            "Train Loss: 0.2718, Train Accuracy: 0.9866\n",
            "Val Loss: 0.5643, Val Accuracy: 0.7359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.72      0.72       107\n",
            "           1       0.76      0.75      0.75       124\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.74      0.74      0.74       231\n",
            "\n",
            "Epoch[87/1000]\n",
            "Train Loss: 0.2682, Train Accuracy: 0.9842\n",
            "Val Loss: 0.5654, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.72      0.71       107\n",
            "           1       0.75      0.73      0.74       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[88/1000]\n",
            "Train Loss: 0.2649, Train Accuracy: 0.9858\n",
            "Val Loss: 0.5650, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.71      0.71       107\n",
            "           1       0.75      0.74      0.74       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[89/1000]\n",
            "Train Loss: 0.2608, Train Accuracy: 0.9874\n",
            "Val Loss: 0.5642, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.70      0.70       107\n",
            "           1       0.74      0.74      0.74       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[90/1000]\n",
            "Train Loss: 0.2591, Train Accuracy: 0.9889\n",
            "Val Loss: 0.5607, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.68      0.70       107\n",
            "           1       0.73      0.76      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[91/1000]\n",
            "Train Loss: 0.2561, Train Accuracy: 0.9905\n",
            "Val Loss: 0.5640, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.71      0.71       107\n",
            "           1       0.75      0.74      0.74       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[92/1000]\n",
            "Train Loss: 0.2537, Train Accuracy: 0.9897\n",
            "Val Loss: 0.5605, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.70      0.70       107\n",
            "           1       0.74      0.75      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[93/1000]\n",
            "Train Loss: 0.2543, Train Accuracy: 0.9874\n",
            "Val Loss: 0.5596, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.66      0.69       107\n",
            "           1       0.73      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[94/1000]\n",
            "Train Loss: 0.2506, Train Accuracy: 0.9921\n",
            "Val Loss: 0.5600, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.66      0.69       107\n",
            "           1       0.73      0.77      0.75       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.71      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[95/1000]\n",
            "Train Loss: 0.2468, Train Accuracy: 0.9913\n",
            "Val Loss: 0.5615, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70       107\n",
            "           1       0.74      0.76      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.72      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[96/1000]\n",
            "Train Loss: 0.2428, Train Accuracy: 0.9921\n",
            "Val Loss: 0.5621, Val Accuracy: 0.7273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.70      0.70       107\n",
            "           1       0.74      0.75      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[97/1000]\n",
            "Train Loss: 0.2409, Train Accuracy: 0.9897\n",
            "Val Loss: 0.5621, Val Accuracy: 0.7316\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71       107\n",
            "           1       0.75      0.75      0.75       124\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.73      0.73      0.73       231\n",
            "weighted avg       0.73      0.73      0.73       231\n",
            "\n",
            "Epoch[98/1000]\n",
            "Train Loss: 0.2400, Train Accuracy: 0.9913\n",
            "Val Loss: 0.5647, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.71      0.70       107\n",
            "           1       0.74      0.73      0.73       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[99/1000]\n",
            "Train Loss: 0.2355, Train Accuracy: 0.9929\n",
            "Val Loss: 0.5647, Val Accuracy: 0.7143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.70      0.69       107\n",
            "           1       0.74      0.73      0.73       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.71      0.71      0.71       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[100/1000]\n",
            "Train Loss: 0.2348, Train Accuracy: 0.9913\n",
            "Val Loss: 0.5658, Val Accuracy: 0.7056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.69      0.69       107\n",
            "           1       0.73      0.72      0.72       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[101/1000]\n",
            "Train Loss: 0.2311, Train Accuracy: 0.9921\n",
            "Val Loss: 0.5626, Val Accuracy: 0.7229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.69      0.70       107\n",
            "           1       0.74      0.75      0.74       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[102/1000]\n",
            "Train Loss: 0.2292, Train Accuracy: 0.9913\n",
            "Val Loss: 0.5613, Val Accuracy: 0.7186\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.69      0.69       107\n",
            "           1       0.74      0.74      0.74       124\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.72      0.72      0.72       231\n",
            "weighted avg       0.72      0.72      0.72       231\n",
            "\n",
            "Epoch[103/1000]\n",
            "Train Loss: 0.2291, Train Accuracy: 0.9937\n",
            "Val Loss: 0.5686, Val Accuracy: 0.6970\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.72      0.69       107\n",
            "           1       0.74      0.68      0.71       124\n",
            "\n",
            "    accuracy                           0.70       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.70      0.70      0.70       231\n",
            "\n",
            "Epoch[104/1000]\n",
            "Train Loss: 0.2301, Train Accuracy: 0.9961\n",
            "Val Loss: 0.5660, Val Accuracy: 0.6926\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.70      0.68       107\n",
            "           1       0.73      0.69      0.71       124\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.69      0.69      0.69       231\n",
            "weighted avg       0.69      0.69      0.69       231\n",
            "\n",
            "Epoch[105/1000]\n",
            "Train Loss: 0.2245, Train Accuracy: 0.9937\n",
            "Val Loss: 0.5692, Val Accuracy: 0.6883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.72      0.68       107\n",
            "           1       0.73      0.66      0.69       124\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.69      0.69      0.69       231\n",
            "weighted avg       0.69      0.69      0.69       231\n",
            "\n",
            "Epoch[106/1000]\n",
            "Train Loss: 0.2211, Train Accuracy: 0.9945\n",
            "Val Loss: 0.5657, Val Accuracy: 0.7056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.69      0.69       107\n",
            "           1       0.73      0.72      0.72       124\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.71      0.71      0.71       231\n",
            "\n",
            "Epoch[107/1000]\n",
            "Train Loss: 0.2205, Train Accuracy: 0.9937\n",
            "Val Loss: 0.5675, Val Accuracy: 0.7013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.70      0.68       107\n",
            "           1       0.73      0.70      0.72       124\n",
            "\n",
            "    accuracy                           0.70       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.70      0.70      0.70       231\n",
            "\n",
            "Epoch[108/1000]\n",
            "Train Loss: 0.2155, Train Accuracy: 0.9945\n",
            "Val Loss: 0.5690, Val Accuracy: 0.7013\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.70      0.68       107\n",
            "           1       0.73      0.70      0.72       124\n",
            "\n",
            "    accuracy                           0.70       231\n",
            "   macro avg       0.70      0.70      0.70       231\n",
            "weighted avg       0.70      0.70      0.70       231\n",
            "\n",
            "Epoch[109/1000]\n",
            "Train Loss: 0.2159, Train Accuracy: 0.9976\n",
            "Val Loss: 0.5696, Val Accuracy: 0.6883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.71      0.68       107\n",
            "           1       0.73      0.67      0.70       124\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.69      0.69      0.69       231\n",
            "weighted avg       0.69      0.69      0.69       231\n",
            "\n",
            "Epoch[110/1000]\n",
            "Train Loss: 0.2131, Train Accuracy: 0.9937\n",
            "Val Loss: 0.5721, Val Accuracy: 0.6797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.71      0.67       107\n",
            "           1       0.72      0.65      0.69       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.68      0.68       231\n",
            "weighted avg       0.68      0.68      0.68       231\n",
            "\n",
            "Epoch[111/1000]\n",
            "Train Loss: 0.2108, Train Accuracy: 0.9937\n",
            "Val Loss: 0.5693, Val Accuracy: 0.6883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.71      0.68       107\n",
            "           1       0.73      0.67      0.70       124\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.69      0.69      0.69       231\n",
            "weighted avg       0.69      0.69      0.69       231\n",
            "\n",
            "Epoch[112/1000]\n",
            "Train Loss: 0.2079, Train Accuracy: 0.9961\n",
            "Val Loss: 0.5741, Val Accuracy: 0.6840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.71      0.68       107\n",
            "           1       0.73      0.66      0.69       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.69      0.68       231\n",
            "weighted avg       0.69      0.68      0.68       231\n",
            "\n",
            "Epoch[113/1000]\n",
            "Train Loss: 0.2056, Train Accuracy: 0.9984\n",
            "Val Loss: 0.5734, Val Accuracy: 0.6840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.71      0.68       107\n",
            "           1       0.73      0.66      0.69       124\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.68      0.69      0.68       231\n",
            "weighted avg       0.69      0.68      0.68       231\n",
            "\n",
            "Early stopping at epoch 114\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_model(model, criterion, optimizer, train_loader, val_loader, device, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "u0YNHS3E_w_S",
        "outputId": "1df21673-5581-466b-8eb0-3ff4001fb211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7534\n",
            "F1 Score: 0.7599\n",
            "Precision: 0.7500\n",
            "Recall: 0.7701\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/oklEQVR4nO3deVyU9f7//+egMiAKiBtQimumZu6ZWi4fKbdMszLMEs0lyyVDzTzHPZVyzyU9eirNrNOqlZpLLlkncsdMzTQxPSauIYGACtfvj37Ot/GNxijDgPO4n9t1uzXXdc11vWZux3r5fL+v99gsy7IEAAAA/IWPpwsAAABA/kOTCAAAAANNIgAAAAw0iQAAADDQJAIAAMBAkwgAAAADTSIAAAAMNIkAAAAw0CQCAADAQJMI4LoOHjyoBx98UEFBQbLZbFq+fHmuXv/IkSOy2WxatGhRrl63IGvRooVatGjh6TIAeDmaRKAA+OWXX/Tss8+qUqVK8vPzU2BgoJo2barXX39daWlpbr13dHS09uzZo4kTJ2rJkiVq0KCBW++Xl3r06CGbzabAwMBsv8eDBw/KZrPJZrNp6tSpLl//t99+09ixYxUfH58L1QJA3irs6QIAXN/KlSv1+OOPy263q3v37rrrrrt08eJFffvttxo2bJj27t2rBQsWuOXeaWlpiouL0z//+U8NGDDALfeIiIhQWlqaihQp4pbr/53ChQvrwoUL+uKLL9SlSxenY0uXLpWfn5/S09Nv6Nq//fabxo0bpwoVKqhOnTo5ft/atWtv6H4AkJtoEoF8LCEhQVFRUYqIiNCGDRsUFhbmONa/f38dOnRIK1eudNv9T58+LUkKDg522z1sNpv8/Pzcdv2/Y7fb1bRpU73//vtGk/jee++pffv2+uSTT/KklgsXLqho0aLy9fXNk/sBwPUw3AzkY5MnT1ZKSorefPNNpwbxiipVquiFF15wvL58+bJeeeUVVa5cWXa7XRUqVNA//vEPZWRkOL2vQoUKeuihh/Ttt9/qnnvukZ+fnypVqqR33nnHcc7YsWMVEREhSRo2bJhsNpsqVKgg6c9h2iv//Fdjx46VzWZz2rdu3Trdd999Cg4OVrFixVStWjX94x//cBy/1pzEDRs26P7771dAQICCg4PVsWNH7d+/P9v7HTp0SD169FBwcLCCgoLUs2dPXbhw4dpf7FWefPJJffnll0pKSnLs27Ztmw4ePKgnn3zSOP/cuXMaOnSoatWqpWLFiikwMFBt27bV7t27Heds2rRJDRs2lCT17NnTMWx95XO2aNFCd911l3bs2KFmzZqpaNGiju/l6jmJ0dHR8vPzMz5/69atVaJECf322285/qwAkFM0iUA+9sUXX6hSpUpq0qRJjs7v3bu3Ro8erXr16mnGjBlq3ry5YmNjFRUVZZx76NAhPfbYY3rggQc0bdo0lShRQj169NDevXslSZ07d9aMGTMkSV27dtWSJUs0c+ZMl+rfu3evHnroIWVkZGj8+PGaNm2aHn74Yf33v/+97vu++uortW7dWqdOndLYsWMVExOj7777Tk2bNtWRI0eM87t06aI//vhDsbGx6tKlixYtWqRx48bluM7OnTvLZrPp008/dex77733dOedd6pevXrG+YcPH9by5cv10EMPafr06Ro2bJj27Nmj5s2bOxq26tWra/z48ZKkvn37asmSJVqyZImaNWvmuM7Zs2fVtm1b1alTRzNnzlTLli2zre/1119X6dKlFR0drczMTEnSv/71L61du1azZ89WeHh4jj8rAOSYBSBfOn/+vCXJ6tixY47Oj4+PtyRZvXv3dto/dOhQS5K1YcMGx76IiAhLkrV582bHvlOnTll2u90aMmSIY19CQoIlyZoyZYrTNaOjo62IiAijhjFjxlh//dfKjBkzLEnW6dOnr1n3lXu8/fbbjn116tSxypQpY509e9axb/fu3ZaPj4/VvXt3437PPPOM0zUfeeQRq2TJkte8518/R0BAgGVZlvXYY49ZrVq1sizLsjIzM63Q0FBr3Lhx2X4H6enpVmZmpvE57Ha7NX78eMe+bdu2GZ/tiubNm1uSrPnz52d7rHnz5k771qxZY0myJkyYYB0+fNgqVqyY1alTp7/9jABwo0gSgXwqOTlZklS8ePEcnb9q1SpJUkxMjNP+IUOGSJIxd7FGjRq6//77Ha9Lly6tatWq6fDhwzdc89WuzGX87LPPlJWVlaP3nDhxQvHx8erRo4dCQkIc+++++2498MADjs/5V/369XN6ff/99+vs2bOO7zAnnnzySW3atEmJiYnasGGDEhMTsx1qlv6cx+jj8+e/PjMzM3X27FnHUPrOnTtzfE+73a6ePXvm6NwHH3xQzz77rMaPH6/OnTvLz89P//rXv3J8LwBwFU0ikE8FBgZKkv74448cnf/rr7/Kx8dHVapUcdofGhqq4OBg/frrr077y5cvb1yjRIkS+v3332+wYtMTTzyhpk2bqnfv3ipbtqyioqL04YcfXrdhvFJntWrVjGPVq1fXmTNnlJqa6rT/6s9SokQJSXLps7Rr107FixfXBx98oKVLl6phw4bGd3lFVlaWZsyYoapVq8put6tUqVIqXbq0fvjhB50/fz7H97zttttcekhl6tSpCgkJUXx8vGbNmqUyZcrk+L0A4CqaRCCfCgwMVHh4uH788UeX3nf1gyPXUqhQoWz3W5Z1w/e4Ml/uCn9/f23evFlfffWVnn76af3www964okn9MADDxjn3oyb+SxX2O12de7cWYsXL9ayZcuumSJK0qRJkxQTE6NmzZrp3Xff1Zo1a7Ru3TrVrFkzx4mp9Of344pdu3bp1KlTkqQ9e/a49F4AcBVNIpCPPfTQQ/rll18UFxf3t+dGREQoKytLBw8edNp/8uRJJSUlOZ5Uzg0lSpRwehL4iqvTSkny8fFRq1atNH36dO3bt08TJ07Uhg0btHHjxmyvfaXOAwcOGMd++uknlSpVSgEBATf3Aa7hySef1K5du/THH39k+7DPFR9//LFatmypN998U1FRUXrwwQcVGRlpfCc5bdhzIjU1VT179lSNGjXUt29fTZ48Wdu2bcu16wPA1WgSgXzspZdeUkBAgHr37q2TJ08ax3/55Re9/vrrkv4cLpVkPIE8ffp0SVL79u1zra7KlSvr/Pnz+uGHHxz7Tpw4oWXLljmdd+7cOeO9VxaVvnpZnivCwsJUp04dLV682Knp+vHHH7V27VrH53SHli1b6pVXXtGcOXMUGhp6zfMKFSpkpJQfffSRjh8/7rTvSjObXUPtquHDh+vo0aNavHixpk+frgoVKig6Ovqa3yMA3CwW0wbyscqVK+u9997TE088oerVqzv94sp3332njz76SD169JAk1a5dW9HR0VqwYIGSkpLUvHlzbd26VYsXL1anTp2uubzKjYiKitLw4cP1yCOPaNCgQbpw4YLmzZunO+64w+nBjfHjx2vz5s1q3769IiIidOrUKb3xxhu6/fbbdd99913z+lOmTFHbtm3VuHFj9erVS2lpaZo9e7aCgoI0duzYXPscV/Px8dHIkSP/9ryHHnpI48ePV8+ePdWkSRPt2bNHS5cuVaVKlZzOq1y5soKDgzV//nwVL15cAQEBatSokSpWrOhSXRs2bNAbb7yhMWPGOJbkefvtt9WiRQuNGjVKkydPdul6AJAjHn66GkAO/Pzzz1afPn2sChUqWL6+vlbx4sWtpk2bWrNnz7bS09Md5126dMkaN26cVbFiRatIkSJWuXLlrBEjRjidY1l/LoHTvn174z5XL71yrSVwLMuy1q5da911112Wr6+vVa1aNevdd981lsBZv3691bFjRys8PNzy9fW1wsPDra5du1o///yzcY+rl4n56quvrKZNm1r+/v5WYGCg1aFDB2vfvn1O51y539VL7Lz99tuWJCshIeGa36llOS+Bcy3XWgJnyJAhVlhYmOXv7281bdrUiouLy3bpms8++8yqUaOGVbhwYafP2bx5c6tmzZrZ3vOv10lOTrYiIiKsevXqWZcuXXI678UXX7R8fHysuLi4634GALgRNstyYWY3AAAAvAJzEgEAAGCgSQQAAICBJhEAAAAGmkQAAAAYaBIBAABgoEkEAACAgSYRAAAAhlvyF1f828/ydAkA3OS3j/p7ugQAblKiaCGP3du/7gC3XTtt1xy3XdudSBIBAABguCWTRAAAAJfYyM2uRpMIAABgs3m6gnyHthkAAAAGkkQAAACGmw18IwAAADCQJAIAADAn0UCSCAAAAANJIgAAAHMSDXwjAAAAMJAkAgAAMCfRQJMIAADAcLOBbwQAAAAGmkQAAACbzX2bizZv3qwOHTooPDxcNptNy5cvv+a5/fr1k81m08yZM532nzt3Tt26dVNgYKCCg4PVq1cvpaSkuFQHTSIAAEA+kpqaqtq1a2vu3LnXPW/ZsmX6/vvvFR4ebhzr1q2b9u7dq3Xr1mnFihXavHmz+vbt61IdzEkEAADIR3MS27Ztq7Zt2173nOPHj2vgwIFas2aN2rdv73Rs//79Wr16tbZt26YGDRpIkmbPnq127dpp6tSp2TaV2ck/3wgAAMAtKCMjQ8nJyU5bRkbGDV8vKytLTz/9tIYNG6aaNWsax+Pi4hQcHOxoECUpMjJSPj4+2rJlS47vQ5MIAADgxjmJsbGxCgoKctpiY2NvuNTXXntNhQsX1qBBg7I9npiYqDJlyjjtK1y4sEJCQpSYmJjj+zDcDAAA4EYjRoxQTEyM0z673X5D19qxY4def/117dy5UzY3r+1IkwgAAODGOYl2u/2Gm8KrffPNNzp16pTKly/v2JeZmakhQ4Zo5syZOnLkiEJDQ3Xq1Cmn912+fFnnzp1TaGhoju9FkwgAAFBAfnHl6aefVmRkpNO+1q1b6+mnn1bPnj0lSY0bN1ZSUpJ27Nih+vXrS5I2bNigrKwsNWrUKMf3okkEAADIR1JSUnTo0CHH64SEBMXHxyskJETly5dXyZIlnc4vUqSIQkNDVa1aNUlS9erV1aZNG/Xp00fz58/XpUuXNGDAAEVFReX4yWaJJhEAACBfLYGzfft2tWzZ0vH6ynzG6OhoLVq0KEfXWLp0qQYMGKBWrVrJx8dHjz76qGbNmuVSHTSJAAAA+UiLFi1kWVaOzz9y5IixLyQkRO+9995N1UGTCAAAkI+SxPyCbwQAAAAGkkQAAACfgvF0c14iSQQAAICBJBEAAIA5iQaaRAAAgAKymHZeom0GAACAgSQRAACA4WYD3wgAAAAMJIkAAADMSTSQJAIAAMBAkggAAMCcRAPfCAAAAAwkiQAAAMxJNNAkAgAAMNxs4BsBAACAgSQRAACA4WYDSSIAAAAMJIkAAADMSTTwjQAAAMBAkggAAMCcRANJIgAAAAwkiQAAAMxJNNAkAgAA0CQa+EYAAABgIEkEAADgwRUDSSIAAAAMJIkAAADMSTTwjQAAAMBAkggAAMCcRANJIgAAAAwkiQAAAMxJNNAkAgAAMNxsoG0GAACAgSQRAAB4PRtJooEkEQAAAAaSRAAA4PVIEk0kiQAAADCQJAIAABAkGkgSAQAAYCBJBAAAXo85iSaaRAAA4PVoEk0MNwMAAMBAkggAALweSaKJJBEAAAAGkkQAAOD1SBJNJIkAAAAwkCQCAAAQJBpIEgEAAGAgSQQAAF6POYkmkkQAAAAYSBIBAIDXI0k00SQCAACvR5NoYrgZAAAABpJEAADg9UgSTSSJAAAAMJAkAgAAECQaSBIBAABgIEkEAABejzmJJpJEAAAAGEgSAQCA1yNJNNEkAgAAr0eTaGK4GQAAAAaSRAAAAIJEA0kiAAAADCSJAADA6zEn0USSCAAAAANJIgAA8HokiSaSRAAAABhIEgEAgNcjSTTRJAIAAK9Hk2hiuBkAAAAGkkQAAACCRANJIgAAAAwkiQAAwOsxJ9FEkggAAAADSSIAAPB6JIkmkkQAAAAYSBIBAIDXI0k00SQCAADQIxoYbgYAAICBJhEAAHg9m83mts1VmzdvVocOHRQeHi6bzably5c7jl26dEnDhw9XrVq1FBAQoPDwcHXv3l2//fab0zXOnTunbt26KTAwUMHBwerVq5dSUlJcqoMmEQAAIB9JTU1V7dq1NXfuXOPYhQsXtHPnTo0aNUo7d+7Up59+qgMHDujhhx92Oq9bt27au3ev1q1bpxUrVmjz5s3q27evS3UwJxEAAHi9/PTgStu2bdW2bdtsjwUFBWndunVO++bMmaN77rlHR48eVfny5bV//36tXr1a27ZtU4MGDSRJs2fPVrt27TR16lSFh4fnqA6SRAAAADfKyMhQcnKy05aRkZFr1z9//rxsNpuCg4MlSXFxcQoODnY0iJIUGRkpHx8fbdmyJcfXpUlEvtS0Zrg+Ht1Bh995RmkrB6nDvZWcjv/zyUaKn/+UznzynH77oK9WTuykhtXKZnst38KF9P3srkpbOUh3VyqVF+UDuEHvvLVQ99atoRlTYh37zp45rbEjh6td5P1q0bi+und9VBu+WuvBKnErcuecxNjYWAUFBTltsbGxf19UDqSnp2v48OHq2rWrAgMDJUmJiYkqU6aM03mFCxdWSEiIEhMTc3xtmkTkSwF+RbQn4bQGz9uU7fFDx3/Xi/O/VoP+S9Vq2Mf69eQf+uKVTioV6G+cO+mZpjpxNtXNFQO4Wfv27tGyTz5UlarVnPaPGzVCR48c0ZSZc7X0o+Vq8X8PaOTwGB34aZ+HKgVcM2LECJ0/f95pGzFixE1f99KlS+rSpYssy9K8efNyoVJnNInIl9bu+FXjlnyvz+MOZ3v8g69/1sb4YzqSmKz9R89p+MJvFBRg110VSzqd92D9CLWqV14j3vw2L8oGcIMuXEjVmH+8pBGjxqn4/5+GXLFn9y49HtVNNe+6W7fdXk7P9OmnYsWL66d9NInIPe5MEu12uwIDA502u91+U/VeaRB//fVXrVu3zpEiSlJoaKhOnTrldP7ly5d17tw5hYaG5vgeHm0Sz5w5o8mTJ+uRRx5R48aN1bhxYz3yyCOaMmWKTp8+7cnSUIAUKeyjXm1rKiklQ3sSzjj2lwn21xuDWqnX1LW6kHHJgxUC+DtTYyeo6f3Ndc+9TYxjtWrX1Vdrv9T580nKysrSutWrdDHjouo1aOiBSnHLsrlxy2VXGsSDBw/qq6++UsmSzgFJ48aNlZSUpB07djj2bdiwQVlZWWrUqFGO7+Oxp5u3bdum1q1bq2jRooqMjNQdd9whSTp58qRmzZqlV199VWvWrHGadJmdjIwMY/KnlXlZtkI8uH2ra9uwgt4Z3kZF7UWUeC5VD41cprPJ6Y7jC158QAtX7dHOQ6dUvkxxD1YK4HrWrV6lAz/t01vvfpjt8YmTp2vk8CFq3aKJChUuLD8/P702fZbKlY/I40qBvJGSkqJDhw45XickJCg+Pl4hISEKCwvTY489pp07d2rFihXKzMx0zDMMCQmRr6+vqlevrjZt2qhPnz6aP3++Ll26pAEDBigqKirHTzZLHmwSBw4cqMcff1zz5883Hju3LEv9+vXTwIEDFRcXd93rxMbGaty4cU77ClVpoyJ3ZP/oOG4dX//wPzUa+L5KBfqrZ5uaevfltmoW86FOn0/T8x1qq7i/r6Z8tN3TZQK4jpOJJzR9Sqxmzfv3NYff/jV3lv74I1mz57+p4OAS+nrTev3zpRjNf2uJqlS9I48rxq0qPy2Bs337drVs2dLxOiYmRpIUHR2tsWPH6vPPP5ck1alTx+l9GzduVIsWLSRJS5cu1YABA9SqVSv5+Pjo0Ucf1axZs1yqw2ZZlnXjH+PG+fv7a9euXbrzzjuzPf7TTz+pbt26SktLu+51sksSy3T5N0niLSRt5SB1eWWFvvg++/mJV+xZ0F2L1+3T1I+268OR7dXunor66/+5Cxfy0eXMLP1n4wH1mbHumtdB/vbbR/09XQJy0dcbv9LwmEEqVKiQY19mZqZsNpt8fHz0wbKVeuzhNnrv489UqXJVxzkDnn1G5cqV1/CRYz1QNdylRNFCf3+Sm1SKWeW2ax+e3s5t13Ynj3VSoaGh2rp16zWbxK1bt6ps2eyXNPkru91u/O2TBtE7+fjYZC/y579ghvzra41d8v9S6LCQYloxoZOefvVLbTtw0lMlArhKg3saa+lHnzntmzDmn4qoWFFP9+it9PQ/p5DYbM5T6AsVKqQsz2QcuEXlpyQxv/BYNzV06FD17dtXO3bsUKtWrRwN4cmTJ7V+/XotXLhQU6dO9VR58LAAvyKqHB7keF0hNFB3Vyql3/9I19nkdA1/oqFWbklQ4rlUlQzy07Pt71Z4yQB9+u1BSdKx086/T5mS9ueDK4cTz+v4Wdd+uxKA+wQEBKhylapO+/z8/RUUFKzKVarq8qVLur1ceb02YawGxgxTUFCwvt64Xlu//07TXn/DQ1UD3sFjTWL//v1VqlQpzZgxQ2+88YYyMzMl/fm3w/r162vRokXq0qWLp8qDh9WrWkZrX33U8Xpyn2aSpCVf7dPAORtVrVwJPdWqukoG+etccpq2HzylyJc+1v6j5zxVMgA3KFykiKbPnq83Zs3Q0Bf6K+3CBd1errxGj49Vk/ube7o83EIIEk0em5P4V5cuXdKZM38uXVKqVCkVKVLkpq7n3961iZkACg7mJAK3Lk/OSawy9Eu3XfvQ1IL5MG2+mLxXpEgRhYWFeboMAADgpZiTaMoXTSIAAIAn0SOa+Fk+AAAAGEgSAQCA12O42USSCAAAAANJIgAA8HoEiSaSRAAAABhIEgEAgNfz8SFKvBpJIgAAAAwkiQAAwOsxJ9FEkwgAALweS+CYGG4GAACAgSQRAAB4PYJEE0kiAAAADCSJAADA6zEn0USSCAAAAANJIgAA8HokiSaSRAAAABhIEgEAgNcjSDTRJAIAAK/HcLOJ4WYAAAAYSBIBAIDXI0g0kSQCAADAQJIIAAC8HnMSTSSJAAAAMJAkAgAAr0eQaCJJBAAAgIEkEQAAeD3mJJpIEgEAAGAgSQQAAF6PINFEkwgAALwew80mhpsBAABgIEkEAABejyDRRJIIAAAAA0kiAADwesxJNJEkAgAAwECSCAAAvB5BookkEQAAAAaSRAAA4PWYk2iiSQQAAF6PHtHEcDMAAAAMJIkAAMDrMdxsIkkEAACAgSQRAAB4PZJEE0kiAAAADCSJAADA6xEkmkgSAQAAYCBJBAAAXo85iSaaRAAA4PXoEU0MNwMAAMBAkggAALwew80mkkQAAAAYSBIBAIDXI0g0kSQCAADAQJIIAAC8ng9RooEkEQAAAAaSRAAA4PUIEk00iQAAwOuxBI6J4WYAAAAYSBIBAIDX8yFINJAkAgAAwECSCAAAvB5zEk0kiQAAADCQJAIAAK9HkGgiSQQAAICBJBEAAHg9m4gSr0aTCAAAvB5L4JgYbgYAAICBJBEAAHg9lsAxkSQCAADAQJIIAAC8HkGiiSQRAAAABpJEAADg9XyIEg0uJ4mLFy/WypUrHa9feuklBQcHq0mTJvr1119ztTgAAAB4hstN4qRJk+Tv7y9JiouL09y5czV58mSVKlVKL774Yq4XCAAA4G42m/u2gsrl4eZjx46pSpUqkqTly5fr0UcfVd++fdW0aVO1aNEit+sDAABwO5bAMbmcJBYrVkxnz56VJK1du1YPPPCAJMnPz09paWm5Wx0AAICX2bx5szp06KDw8HDZbDYtX77c6bhlWRo9erTCwsLk7++vyMhIHTx40Omcc+fOqVu3bgoMDFRwcLB69eqllJQUl+pwuUl84IEH1Lt3b/Xu3Vs///yz2rVrJ0nau3evKlSo4OrlAAAAPC4/DTenpqaqdu3amjt3brbHJ0+erFmzZmn+/PnasmWLAgIC1Lp1a6WnpzvO6datm/bu3at169ZpxYoV2rx5s/r27etSHS4PN8+dO1cjR47UsWPH9Mknn6hkyZKSpB07dqhr166uXg4AAAB/0bZtW7Vt2zbbY5ZlaebMmRo5cqQ6duwoSXrnnXdUtmxZLV++XFFRUdq/f79Wr16tbdu2qUGDBpKk2bNnq127dpo6darCw8NzVIfLTWJwcLDmzJlj7B83bpyrlwIAAMgX3LkETkZGhjIyMpz22e122e12l6+VkJCgxMRERUZGOvYFBQWpUaNGiouLU1RUlOLi4hQcHOxoECUpMjJSPj4+2rJlix555JEc3StHTeIPP/yQ4+LvvvvuHJ8LAABwq4uNjTXCtDFjxmjs2LEuXysxMVGSVLZsWaf9ZcuWdRxLTExUmTJlnI4XLlxYISEhjnNyIkdNYp06dWSz2WRZVrbHrxyz2WzKzMzM8c0BAADyA3c+2zxixAjFxMQ47buRFDGv5ahJTEhIcHcdAAAAt6QbHVrOTmhoqCTp5MmTCgsLc+w/efKk6tSp4zjn1KlTTu+7fPmyzp0753h/TuSoSYyIiMjxBQEAAAqagrJOYsWKFRUaGqr169c7msLk5GRt2bJFzz33nCSpcePGSkpK0o4dO1S/fn1J0oYNG5SVlaVGjRrl+F4uL4EjSUuWLFHTpk0VHh7u+Cm+mTNn6rPPPruRywEAAHiUj819m6tSUlIUHx+v+Ph4SX+O6MbHx+vo0aOy2WwaPHiwJkyYoM8//1x79uxR9+7dFR4erk6dOkmSqlevrjZt2qhPnz7aunWr/vvf/2rAgAGKiorK8ZPN0g00ifPmzVNMTIzatWunpKQkxxzE4OBgzZw509XLAQAA4C+2b9+uunXrqm7dupKkmJgY1a1bV6NHj5YkvfTSSxo4cKD69u2rhg0bKiUlRatXr5afn5/jGkuXLtWdd96pVq1aqV27drrvvvu0YMECl+qwWdd6GuUaatSooUmTJqlTp04qXry4du/erUqVKunHH39UixYtdObMGZcKcAf/9rM8XQIAN/nto/6eLgGAm5QoWshj937q3d1uu/a7T9V227XdyeUkMSEhwdHZ/pXdbldqamquFAUAAADPcrlJrFixomOM/K9Wr16t6tWr50ZNAAAAeSo//SxffuHyL67ExMSof//+Sk9Pl2VZ2rp1q95//33Fxsbq3//+tztqBAAAQB5zuUns3bu3/P39NXLkSF24cEFPPvmkwsPD9frrrysqKsodNQIAALhVQVkCJy+53CRKUrdu3dStWzdduHBBKSkpxk+/AAAAoGC7oSZRkk6dOqUDBw5I+rP7Ll26dK4VBQAAkJduZD3DW53LD6788ccfevrppxUeHq7mzZurefPmCg8P11NPPaXz58+7o0YAAAC3stlsbtsKKpebxN69e2vLli1auXKlkpKSlJSUpBUrVmj79u169tln3VEjAAAA8pjLw80rVqzQmjVrdN999zn2tW7dWgsXLlSbNm1ytTgAAIC8UHDzPvdxOUksWbKkgoKCjP1BQUEqUaJErhQFAAAAz3K5SRw5cqRiYmKUmJjo2JeYmKhhw4Zp1KhRuVocAABAXvCx2dy2FVQ5Gm6uW7eu08TLgwcPqnz58ipfvrwk6ejRo7Lb7Tp9+jTzEgEAAG4BOWoSO3Xq5OYyAAAAPKcAB35uk6MmccyYMe6uAwAAAPnIDS+mDQAAcKsoyOsZuovLTWJmZqZmzJihDz/8UEePHtXFixedjp87dy7XigMAAIBnuPx087hx4zR9+nQ98cQTOn/+vGJiYtS5c2f5+Pho7NixbigRAADAvWw2920FlctN4tKlS7Vw4UINGTJEhQsXVteuXfXvf/9bo0eP1vfff++OGgEAANyKJXBMLjeJiYmJqlWrliSpWLFijt9rfuihh7Ry5crcrQ4AAAAe4XKTePvtt+vEiROSpMqVK2vt2rWSpG3btslut+dudQAAAHmA4WaTy03iI488ovXr10uSBg4cqFGjRqlq1arq3r27nnnmmVwvEAAAAHnP5aebX331Vcc/P/HEE4qIiNB3332nqlWrqkOHDrlaHAAAQF5gCRyTy0ni1e69917FxMSoUaNGmjRpUm7UBAAAAA+zWZZl5caFdu/erXr16ikzMzM3LndT0i97ugIA7lKi4QBPlwDATdJ2zfHYvQcu2++2a89+pLrbru1ON50kAgAA4NbDz/IBAACvx5xEE00iAADwej70iIYcN4kxMTHXPX769OmbLgYAAAD5Q46bxF27dv3tOc2aNbupYgAAADyBJNGU4yZx48aN7qwDAAAA+QhzEgEAgNfjwRUTS+AAAADAQJIIAAC8HnMSTSSJAAAAMJAkAgAAr8eURNMNJYnffPONnnrqKTVu3FjHjx+XJC1ZskTffvttrhYHAACQF3xsNrdtBZXLTeInn3yi1q1by9/fX7t27VJGRoYk6fz585o0aVKuFwgAAIC853KTOGHCBM2fP18LFy5UkSJFHPubNm2qnTt35mpxAAAAecHHjVtB5XLtBw4cyPaXVYKCgpSUlJQbNQEAAMDDXG4SQ0NDdejQIWP/t99+q0qVKuVKUQAAAHnJZnPfVlC53CT26dNHL7zwgrZs2SKbzabffvtNS5cu1dChQ/Xcc8+5o0YAAADkMZeXwHn55ZeVlZWlVq1a6cKFC2rWrJnsdruGDh2qgQMHuqNGAAAAtyrITyG7i8tNos1m0z//+U8NGzZMhw4dUkpKimrUqKFixYq5oz4AAAB4wA0vpu3r66saNWrkZi0AAAAeQZBocrlJbNmypWzX+SY3bNhwUwUBAADkNX672eRyk1inTh2n15cuXVJ8fLx+/PFHRUdH51ZdAAAA8CCXm8QZM2Zku3/s2LFKSUm56YIAAADyGg+umHJtIfCnnnpKb731Vm5dDgAAAB50ww+uXC0uLk5+fn65dTkAAIA8Q5BocrlJ7Ny5s9Nry7J04sQJbd++XaNGjcq1wgAAAOA5LjeJQUFBTq99fHxUrVo1jR8/Xg8++GCuFQYAAJBXeLrZ5FKTmJmZqZ49e6pWrVoqUaKEu2oCAACAh7n04EqhQoX04IMPKikpyU3lAAAA5D2bG/9XULn8dPNdd92lw4cPu6MWAAAAj/CxuW8rqFxuEidMmKChQ4dqxYoVOnHihJKTk502AAAAFHw5npM4fvx4DRkyRO3atZMkPfzww04/z2dZlmw2mzIzM3O/SgAAADcqyImfu+S4SRw3bpz69eunjRs3urMeAAAA5AM5bhIty5IkNW/e3G3FAAAAeIKN1bQNLs1J5AsEAADwDi6tk3jHHXf8baN47ty5myoIAAAgrzEn0eRSkzhu3DjjF1cAAABw63GpSYyKilKZMmXcVQsAAIBHMKPOlOMmkfmIAADgVuVDn2PI8YMrV55uBgAAwK0vx0liVlaWO+sAAADwGB5cMbn8s3wAAAC49bn04AoAAMCtiCmJJpJEAAAAGEgSAQCA1/MRUeLVSBIBAABgIEkEAABejzmJJppEAADg9VgCx8RwMwAAAAwkiQAAwOvxs3wmkkQAAAAYSBIBAIDXI0g0kSQCAADAQJIIAAC8HnMSTSSJAAAAMJAkAgAAr0eQaKJJBAAAXo+hVRPfCQAAQD6RmZmpUaNGqWLFivL391flypX1yiuvyLIsxzmWZWn06NEKCwuTv7+/IiMjdfDgwVyvhSYRAAB4PZvN5rbNFa+99prmzZunOXPmaP/+/Xrttdc0efJkzZ4923HO5MmTNWvWLM2fP19btmxRQECAWrdurfT09Fz9ThhuBgAAcKOMjAxlZGQ47bPb7bLb7ca53333nTp27Kj27dtLkipUqKD3339fW7dulfRnijhz5kyNHDlSHTt2lCS98847Klu2rJYvX66oqKhcq5skEQAAeD2bG7fY2FgFBQU5bbGxsdnW0aRJE61fv14///yzJGn37t369ttv1bZtW0lSQkKCEhMTFRkZ6XhPUFCQGjVqpLi4uFz8RkgSAQAA3GrEiBGKiYlx2pddiihJL7/8spKTk3XnnXeqUKFCyszM1MSJE9WtWzdJUmJioiSpbNmyTu8rW7as41huoUkEAABez52LaV9raDk7H374oZYuXar33ntPNWvWVHx8vAYPHqzw8HBFR0e7rcbs0CQCAADkE8OGDdPLL7/smFtYq1Yt/frrr4qNjVV0dLRCQ0MlSSdPnlRYWJjjfSdPnlSdOnVytRbmJAIAAK/nzjmJrrhw4YJ8fJzbs0KFCikrK0uSVLFiRYWGhmr9+vWO48nJydqyZYsaN27s4t2ujyQRAAB4vfzyiysdOnTQxIkTVb58edWsWVO7du3S9OnT9cwzz0j6c6mewYMHa8KECapataoqVqyoUaNGKTw8XJ06dcrVWmgSAQAA8onZs2dr1KhRev7553Xq1CmFh4fr2Wef1ejRox3nvPTSS0pNTVXfvn2VlJSk++67T6tXr5afn1+u1mKz/rqE9y0i/bKnKwDgLiUaDvB0CQDcJG3XHI/d+/1dx9127a51b3Pbtd2JOYkAAAAwMNwMAAC8HqmZie8EAAAABpJEAADg9Wz55fHmfIQkEQAAAAaSRAAA4PXIEU0kiQAAADCQJAIAAK/HnEQTTSIAAPB6DK2a+E4AAABgIEkEAABej+FmE0kiAAAADCSJAADA65EjmkgSAQAAYCBJBAAAXo8piSaSRAAAABhIEgEAgNfzYVaigSYRAAB4PYabTQw3AwAAwECSCAAAvJ6N4WYDSSIAAAAMJIkAAMDrMSfRRJIIAAAAA0kiAADweiyBYyJJBAAAgIEkEQAAeD3mJJpoEgEAgNejSTQx3AwAAAADSSIAAPB6LKZtIkkEAACAgSQRAAB4PR+CRANJIgAAAAwkiQAAwOsxJ9FEkggAAAADSSIAAPB6rJNookkEAABej+FmE8PNAAAAMJAkAgAAr8cSOCaSRAAAABhIEgEAgNdjTqKJJBEAAAAGmkQUOG8uXKDaNatpcuxEx77xY0erfZtI3VPvbrW47169MOA5JRz+xYNVAriWpvUq6+OZz+rw2olK2zVHHVrcfc1zZ/0zSmm75mjAky2yPe5bpLC+/8/LSts1R3ffcZubKoY3sNnctxVUNIkoUH7c84M+/ug/uuOOak77a9SoqfETYrXsi1Wat+BNWZalfn16KTMz00OVAriWAH+79vx8XINjP7jueQ+3vFv31Kqg304lXfOcSYM76sTp87lcIQCJJhEFyIXUVI0YPkxjxk1QYFCQ07HHujyh+g0a6rbbblf1GjU1YNBgJSae0G/Hj3uoWgDXsva/+zTujRX6fOMP1zwnvHSQpg9/XD3/sUiXLmf/l70Hm9ZQq3ura8SMZe4qFV7E5satoKJJRIExacJ4NWvWXPc2bnLd8y5cuKDPln2q226/XaGhoXlUHYDcYrPZ9OaE7pqxeL32H07M9pwyIcX1xqiu6jXqHV1Iu5jHFeJW5GOzuW0rqPJ1k3js2DE988wz1z0nIyNDycnJTltGRkYeVYi88uWqldq/f58GvTjkmud88P5S3dugrho3rKtvv92sfy18W0V8ffOwSgC5YUjPB3Q5M0tz3990zXMWjH9KCz/+Vjv3Hc27wgAvk6+bxHPnzmnx4sXXPSc2NlZBQUFO25TXYvOoQuSFxBMnNPnViYp9bYrsdvs1z2v30MP64JNlemvxu4qIqKBhQwbzFwaggKlbvZz6d22hvmPeveY5z3dtruJF/TTlrbV5WBludQw3m2yWZVmeuvnnn39+3eOHDx/WkCFDrvvwQUZGhtEIWIXs120mULBsWP+VXhzUX4UKFXLsy8zMlM1mk4+Pj7bt2uN0TJIuXbyo+5rco7HjJqht+4fyumS4UYmGAzxdAnJR2q456vLiAn2x6c/5iQOebKHXhnRWVtb/+09T4cKFlJmZpf+d/F13th+jD6f3UbtmtfTX/3wVLlxIly9n6j9fblef0Uvy/HMgd6TtmuOxe39/KMlt1763SrDbru1OHl1Mu1OnTrLZbLpen2r7m7F8u91sCNMv50p5yCca3XuvPl7+hdO+Mf8coQqVKqlnrz5GgyhJliRZli5eZK4SUJC8t3KbNmw54LTvizf6672VW/XOZ99LkoZM/lhj565wHA8rHaQV8wbo6Zff1rY9R/KyXNxKCnLk5yYebRLDwsL0xhtvqGPHjtkej4+PV/369fO4KuQ3AQHFVLXqHU77/IsWVXBQsKpWvUP/O3ZMa1avUuMmTVWiRIhOnkzUW/9eILvdT/c1a+6hqgFcS4C/ryqXK+14XeG2krr7jtv0e/IFHUv8XefOpzqdf+lypk6eSdbBX09Jko4l/u50POXCn6NJh4+d1vHrLJcDwDUebRLr16+vHTt2XLNJ/LuUEZAkX7uvdu7YrneXLFby+WSVLFVS9es30DtL31fJkiU9XR6Aq9SrEaG1/37B8Xry0EclSUs+//66cxEBd+Jn+UwenZP4zTffKDU1VW3atMn2eGpqqrZv367mzV1LgxhuBm5dzEkEbl2enJO45Rf3LcreqHLQ35+UD3k0Sbz//vuvezwgIMDlBhEAAMBVBXg5Q7fxaJMIAACQH9AjmvL1OokAAADwDJJEAAAAokQDSSIAAAAMJIkAAMDrsQSOiSQRAAAABpJEAADg9VgCx0SSCAAAAANJIgAA8HoEiSaaRAAAALpEA8PNAAAAMJAkAgAAr8cSOCaSRAAAABhIEgEAgNdjCRwTSSIAAAAMJIkAAMDrESSaSBIBAABgIEkEAAAgSjTQJAIAAK/HEjgmhpsBAABgIEkEAABejyVwTCSJAAAAMJAkAgAAr0eQaCJJBAAAgIEkEQAAgCjRQJIIAAAAA0kiAADweqyTaCJJBAAAyEeOHz+up556SiVLlpS/v79q1aql7du3O45blqXRo0crLCxM/v7+ioyM1MGDB3O9DppEAADg9Ww2922u+P3339W0aVMVKVJEX375pfbt26dp06apRIkSjnMmT56sWbNmaf78+dqyZYsCAgLUunVrpaen5+p3wnAzAADwevllsPm1115TuXLl9Pbbbzv2VaxY0fHPlmVp5syZGjlypDp27ChJeuedd1S2bFktX75cUVFRuVYLSSIAAIAbZWRkKDk52WnLyMjI9tzPP/9cDRo00OOPP64yZcqobt26WrhwoeN4QkKCEhMTFRkZ6dgXFBSkRo0aKS4uLlfrpkkEAACwuW+LjY1VUFCQ0xYbG5ttGYcPH9a8efNUtWpVrVmzRs8995wGDRqkxYsXS5ISExMlSWXLlnV6X9myZR3HcgvDzQAAAG40YsQIxcTEOO2z2+3ZnpuVlaUGDRpo0qRJkqS6devqxx9/1Pz58xUdHe32Wv+KJBEAAHg9mxv/Z7fbFRgY6LRdq0kMCwtTjRo1nPZVr15dR48elSSFhoZKkk6ePOl0zsmTJx3HcgtNIgAAQD7RtGlTHThwwGnfzz//rIiICEl/PsQSGhqq9evXO44nJydry5Ytaty4ca7WwnAzAADweq4uVeMuL774opo0aaJJkyapS5cu2rp1qxYsWKAFCxZIkmw2mwYPHqwJEyaoatWqqlixokaNGqXw8HB16tQpV2uhSQQAAMgnGjZsqGXLlmnEiBEaP368KlasqJkzZ6pbt26Oc1566SWlpqaqb9++SkpK0n333afVq1fLz88vV2uxWZZl5eoV84H0y56uAIC7lGg4wNMlAHCTtF1zPHbvnxMvuO3ad4QWddu13YkkEQAAIJ8MN+cnPLgCAAAAA0kiAADwejaiRANJIgAAAAwkiQAAwOvllyVw8hOSRAAAABhIEgEAgNcjSDSRJAIAAMBAkggAAECUaKBJBAAAXo8lcEwMNwMAAMBAkggAALweS+CYSBIBAABgIEkEAABejyDRRJIIAAAAA0kiAAAAUaKBJBEAAAAGkkQAAOD1WCfRRJMIAAC8HkvgmBhuBgAAgIEkEQAAeD2CRBNJIgAAAAwkiQAAwOsxJ9FEkggAAAADSSIAAACzEg0kiQAAADCQJAIAAK/HnEQTTSIAAPB69IgmhpsBAABgIEkEAABej+FmE0kiAAAADCSJAADA69mYlWggSQQAAICBJBEAAIAg0UCSCAAAAANJIgAA8HoEiSaaRAAA4PVYAsfEcDMAAAAMJIkAAMDrsQSOiSQRAAAABpJEAAAAgkQDSSIAAAAMJIkAAMDrESSaSBIBAABgIEkEAABej3USTTSJAADA67EEjonhZgAAABhIEgEAgNdjuNlEkggAAAADTSIAAAAMNIkAAAAwMCcRAAB4PeYkmkgSAQAAYCBJBAAAXo91Ek00iQAAwOsx3GxiuBkAAAAGkkQAAOD1CBJNJIkAAAAwkCQCAAAQJRpIEgEAAGAgSQQAAF6PJXBMJIkAAAAwkCQCAACvxzqJJpJEAAAAGEgSAQCA1yNINNEkAgAA0CUaGG4GAACAgSQRAAB4PZbAMZEkAgAAwECSCAAAvB5L4JhIEgEAAGCwWZZleboI4EZlZGQoNjZWI0aMkN1u93Q5AHIRf74Bz6JJRIGWnJysoKAgnT9/XoGBgZ4uB0Au4s834FkMNwMAAMBAkwgAAAADTSIAAAAMNIko0Ox2u8aMGcOkduAWxJ9vwLN4cAUAAAAGkkQAAAAYaBIBAABgoEkEAACAgSYRAAAABppEFGhz585VhQoV5Ofnp0aNGmnr1q2eLgnATdq8ebM6dOig8PBw2Ww2LV++3NMlAV6JJhEF1gcffKCYmBiNGTNGO3fuVO3atdW6dWudOnXK06UBuAmpqamqXbu25s6d6+lSAK/GEjgosBo1aqSGDRtqzpw5kqSsrCyVK1dOAwcO1Msvv+zh6gDkBpvNpmXLlqlTp06eLgXwOiSJKJAuXryoHTt2KDIy0rHPx8dHkZGRiouL82BlAADcGmgSUSCdOXNGmZmZKlu2rNP+smXLKjEx0UNVAQBw66BJBAAAgIEmEQVSqVKlVKhQIZ08edJp/8mTJxUaGuqhqgAAuHXQJKJA8vX1Vf369bV+/XrHvqysLK1fv16NGzf2YGUAANwaCnu6AOBGxcTEKDo6Wg0aNNA999yjmTNnKjU1VT179vR0aQBuQkpKig4dOuR4nZCQoPj4eIWEhKh8+fIerAzwLiyBgwJtzpw5mjJlihITE1WnTh3NmjVLjRo18nRZAG7Cpk2b1LJlS2N/dHS0Fi1alPcFAV6KJhEAAAAG5iQCAADAQJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQAAADDQJAK4YT169FCnTp0cr1u0aKHBgwfneR2bNm2SzWZTUlKS2+5x9We9EXlRJwDkFppE4BbTo0cP2Ww22Ww2+fr6qkqVKho/frwuX77s9nt/+umneuWVV3J0bl43TBUqVNDMmTPz5F4AcCso7OkCAOS+Nm3a6O2331ZGRoZWrVql/v37q0iRIhoxYoRx7sWLF+Xr65sr9w0JCcmV6wAAPI8kEbgF2e12hYaGKiIiQs8995wiIyP1+eefS/p/w6YTJ05UeHi4qlWrJkk6duyYunTpouDgYIWEhKhjx446cuSI45qZmZmKiYlRcHCwSpYsqZdeeklX//T71cPNGRkZGj58uMqVKye73a4qVarozTff1JEjR9SyZUtJUokSJWSz2dSjRw9JUlZWlmJjY1WxYkX5+/urdu3a+vjjj53us2rVKt1xxx3y9/dXy5Ytneq8EZmZmerVq5fjntWqVdPrr7+e7bnjxo1T6dKlFRgYqH79+unixYuOYzmp/a9+/fVXdejQQSVKlFBAQIBq1qypVatW3dRnAYDcQpIIeAF/f3+dPXvW8Xr9+vUKDAzUunXrJEmXLl1S69at1bhxY33zzTcqXLiwJkyYoDZt2uiHH36Qr6+vpk2bpkWLFumtt95S9erVNW3aNC1btkz/93//d837du/eXXFxcZo1a5Zq166thIQEnTlzRuXKldMnn3yiRx99VAcOHFBgYKD8/f0lSbGxsXr33Xc1f/58Va1aVZs3b9ZTTz2l0qVLq3nz5jp27Jg6d+6s/v37q2/fvtq+fbuGDBlyU99PVlaWbr/9dn300UcqWbKkvvvuO/Xt21dhYWHq0qWL0/fm5+enTZs26ciRI+rZs6dKliypiRMn5qj2q/Xv318XL17U5s2bFRAQoH379qlYsWI39VkAINdYAG4p0dHRVseOHS3LsqysrCxr3bp1lt1ut4YOHeo4XrZsWSsjI8PxniVLlljVqlWzsrKyHPsyMjIsf39/a82aNZZlWVZYWJg1efJkx/FLly5Zt99+u+NelmVZzZs3t1544QXLsizrwIEDliRr3bp12da5ceNGS5L1+++/O/alp6dbRYsWtb777junc3v16mV17drVsizLGjFihFWjRg2n48OHDzeudbWIiAhrxowZ1zx+tf79+1uPPvqo43V0dLQVEhJipaamOvbNmzfPKlasmJWZmZmj2q/+zLVq1bLGjh2b45oAIC+RJAK3oBUrVqhYsWK6dOmSsrKy9OSTT2rs2LGO47Vq1XKah7h7924dOnRIxYsXd7pOenq6fvnlF50/f14nTpxQo0aNHMcKFy6sBg0aGEPOV8THx6tQoULZJmjXcujQIV24cEEPPPCA0/6LFy+qbt26kqT9+/c71SFJjRs3zvE9rmXu3Ll66623dPToUaWlpenixYuqU6eO0zm1a9dW0aJFne6bkpKiY8eOKSUl5W9rv9qgQYP03HPPae3atYqMjNSjjz6qu++++6Y/CwDkBppE4BbUsmVLzZs3T76+vgoPD1fhws5/1AMCApxep6SkqH79+lq6dKlxrdKlS99QDVeGj12RkpIiSVq5cqVuu+02p2N2u/2G6siJ//znPxo6dKimTZumxo0bq3jx4poyZYq2bNmS42vcSO29e/dW69attXLlSq1du1axsbGaNm2aBg4ceOMfBgByCU0icAsKCAhQlSpVcnx+vXr19MEHH6hMmTIKDAzM9pywsDBt2bJFzZo1kyRdvnxZO3bsUL169bI9v1atWsrKytLXX3+tyMhI4/iVJDMzM9Oxr0aNGrLb7Tp69Og1E8jq1as7HsK54vvvv//7D3kd//3vf9WkSRM9//zzjn2//PKLcd7u3buVlpbmaIC///57FStWTOXKlVNISMjf1p6dcuXKqV+/furXr59GjBihhQsX0iQCyBd4uhmAunXrplKlSqljx4765ptvlJCQoE2bNmnQoEH63//+J0l64YUX9Oqrr2r58uX66aef9Pzzz193jcMKFSooOjpazzzzjJYvX+645ocffihJioiIkM1m04oVK3T69GmlpKSoePHiGjp0qF588UUtXrxYv/zyi3bu3KnZs2dr8eLFkqR+/frp4MGDGjZsmA4cOKD33ntPixYtytHnPH78uOLj452233//XVWrVtX27du1Zs0a/fzzzxo1apS2bdtmvP/ixYvq1auX9u3bp1WrVmnMmDEaMGCAfHx8clT71QYPHqw1a9YoISFBO3fu1MaNG1W9evUcfRYAcDtPT4oEkLv++uCKK8dPnDhhde/e3SpVqpRlt9utSpUqWX369LHOnz9vWdafD6q88MILVmBgoBUcHGzFxMRY3bt3v+aDK5ZlWWlpadaLL75ohYWFWb6+vlaVKlWst956y3F8/PjxVmhoqGWz2azo6GjLsv582GbmzJlWtWrVrCJFililS5e2WrdubX399deO933xxRdWlSpVLLvdbt1///3WW2+9laMHVyQZ25IlS6z09HSrR48eVlBQkBUcHGw999xz1ssvv2zVrl3b+N5Gjx5tlSxZ0ipWrJjVp08fKz093XHO39V+9YMrAwYMsCpXrmzZ7XardOnS1tNPP22dOXPmmp8BAPKSzbKuMescAAAAXovhZgAAABhoEgEAAGCgSQQAAICBJhEAAAAGmkQAAAAYaBIBAABgoEkEAACAgSYRAAAABppEAAAAGGgSAQAAYKBJBAAAgOH/A05ad63vNM23AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Testing\n",
        "with torch.no_grad():\n",
        "    x_test_tensor = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
        "\n",
        "    outputs = model(x_test_tensor)\n",
        "    predictions = (outputs > 0.5).float()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions.cpu().numpy())\n",
        "f1 = f1_score(y_test, predictions.cpu().numpy())\n",
        "precision = precision_score(y_test, predictions.cpu().numpy())\n",
        "recall = recall_score(y_test, predictions.cpu().numpy())\n",
        "conf_matrix = confusion_matrix(y_test, predictions.cpu().numpy())\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
